{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nba game predictions and betting \n",
    "\n",
    "The following notebook helps making perdiction on the outcome (Win vs Loss) of a basketball game.\n",
    "The data gathered here are retrieved from my own webscrapping.\n",
    "Some of the packages used are beautiful soup / regex etc (for more insight and upon request, codes can be shared) \n",
    "The major websites used are wikipedia, https://www.sports-reference.com/cbb/, https://www.basketball-reference.com/, ESPN.\n",
    "\n",
    "While webscrapping, data engineering, determinitic models and previous predictions based on the knowledge of the game make a major part of this final product, such prepocessing will not be discussed but could be upon request.\n",
    "\n",
    "Some data: \n",
    "\n",
    "- The age, physicality and experience of the team are aggregated into the feature: H_W_aggr_ ,  Age_Yr_aggr_\n",
    "\n",
    "- Ratings from the previous game are used for defense, offense, shooting etc. and a weight is given for a team on a given day\n",
    "\n",
    "- Exhaustion and Success are computed via score diff, successive victories, game played, game difference with last game.\n",
    "\n",
    "- When teams face each other, each features for team 1 are joined to features for team 2 and the outcome win or loss is predicted with probability\n",
    "\n",
    "- For games happening in the future, deterministic models devised by myself and other such as rolling mean etc help in the determing or predicting the features used for the predictive models (Win/Loss) here.\n",
    "\n",
    "\n",
    "Data from 2000 to 2019 are used here. The results, methods and models here were used on the pre-covid 2020 (events happening in the future at the time) season with a close to 60% success rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43918"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "Seasons1 = pd.read_excel('Seasons.xlsx', encoding = 'latin-1')\n",
    "Seasons2 = pd.read_excel('Seasons2.xlsx', encoding = 'latin-1')\n",
    "Seasons3 = pd.read_excel('Seasons3.xlsx', encoding = 'latin-1')\n",
    "Seasons4 = pd.read_excel('Seasons4.xlsx', encoding = 'latin-1')\n",
    "\n",
    "Seasons_all = pd.concat([Seasons1, Seasons2, Seasons3])\n",
    "#Seasons_all = pd.concat([Seasons1, Seasons2, Seasons3, Seasons4])\n",
    "Seasons_all.reset_index(inplace = True)\n",
    "len(Seasons_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21959"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ind = Seasons_all[['Date_x', 'Win_x','Loss_x']].drop_duplicates().index\n",
    "Seasons_all = Seasons_all[Seasons_all.index.isin(a_ind)]\n",
    "len(Seasons_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "The feautures created are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['index', 'Unnamed: 0', 'Unnamed: 0.1', 'Date_x', 'Win_x', 'Loss_x',\n",
       "       'Up_x', 'Down_x', 'Age_Yr_aggr_Win', 'H_W_aggr_Win', 'TS%_Win',\n",
       "       'OFFRTG_Win', 'DEFRTG_Win', 'Age_Yr_aggr_Loss', 'H_W_aggr_Loss',\n",
       "       'TS%_Loss', 'OFFRTG_Loss', 'DEFRTG_Loss', 'Game_Number',\n",
       "       'Successive_Vic', 'Days_Diff', 'Score_diff', 'Vic',\n",
       "       'Game_Number_2', 'Successive_Vic_2', 'Days_Diff_2', 'Score_diff_2',\n",
       "       'Vic_2', 'Age_Yr_aggr_1', 'H_W_aggr_1', 'TS%_1', 'OFFRTG_1',\n",
       "       'DEFRTG_1', 'Age_Yr_aggr_2', 'H_W_aggr_2', 'TS%_2', 'OFFRTG_2',\n",
       "       'DEFRTG_2', 'Results_1'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seasons_all.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Game_Number', 'Successive_Vic', 'Days_Diff', 'Score_diff', 'Vic',\n",
       "       'Game_Number_2', 'Successive_Vic_2', 'Days_Diff_2', 'Score_diff_2',\n",
       "       'Vic_2', 'Age_Yr_aggr_1', 'H_W_aggr_1', 'TS%_1', 'OFFRTG_1',\n",
       "       'DEFRTG_1', 'Age_Yr_aggr_2', 'H_W_aggr_2', 'TS%_2', 'OFFRTG_2',\n",
       "       'DEFRTG_2', 'Results_1'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seasons_all.iloc[:,18:].columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features and rows\n",
    "\n",
    "After the features are selected the raws are selected since prior analysis suggests game changes on average every 5 years. \n",
    "\n",
    "We then operate different regressions and gridSearch to fin the probabilty of win/loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mod_seasons = Seasons_all.iloc[:,18:].loc[35000:]\n",
    "len(Mod_seasons)\n",
    "\n",
    "#Mod_seasons = Seasons_all.iloc[:,18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7499321196812267 , accuracy: 0.6909917140028141 , params: {'C': 1000.0, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "X = Mod_seasons.loc[:,Mod_seasons.columns != 'Results_1'] # Trainning columns\n",
    "y = Mod_seasons.Results_1 #testing columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) # split for trainning\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_Scl1 = scaler.fit_transform(X_train) #scaling the data since the distances and the weights \n",
    "X_test_Scl1 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#X_train_Scl1 = X_train \n",
    "#X_test_Scl1 = X_test\n",
    "\n",
    "#clf1 = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1)\n",
    "#clf1.fit(X_train,y_train)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=40, tol=5)\n",
    "#lr.fit(X_train,y_train)\n",
    "\n",
    "grid = { 'C': np.power(10.0, np.arange(-30, 30)), 'solver': ['lbfgs'] }\n",
    "\n",
    "grid_AUC_scores = GridSearchCV(lr, param_grid = grid, scoring = 'roc_auc')\n",
    "grid_AUC_scores.fit(X_train_Scl1, y_train)\n",
    "\n",
    "Accuracy = GridSearchCV(lr, grid, scoring='accuracy')\n",
    "Accuracy.fit(X_train_Scl1, y_train)\n",
    "\n",
    "#optimize the scores ROC: sensitivity and AUC: should be above .5 and closer to 1\n",
    "#to differentiate from a dummy classifier. In order to optimize our classification\n",
    "print('AUC:', grid_AUC_scores.best_score_, ', accuracy:', Accuracy.best_score_ , ', params:',grid_AUC_scores.best_params_)\n",
    "\n",
    "#, ', accuracy:', Accuracy.best_score_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forest trees can help refine the model by doing feature selection (Not much gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Columns Accuracy:\n",
      "0.6631171345595354\n",
      "All Columns AUC:\n",
      "0.6644191378208743\n",
      "important Columns:\n",
      "TS%_1\n",
      "OFFRTG_1\n",
      "DEFRTG_1\n",
      "TS%_2\n",
      "OFFRTG_2\n",
      "DEFRTG_2\n",
      "important Columns Accuracy:\n",
      "0.665053242981607\n",
      "important Columns AUC:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6656631713458865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "\n",
    "print(\"All Columns Accuracy:\")\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (4 Features) Model\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"All Columns AUC:\")\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "print(metrics.auc(fpr, tpr))\n",
    "\n",
    "sfm1 = SelectFromModel(clf1, threshold=0.06)\n",
    "sfm1.fit(X_train, y_train)\n",
    "\n",
    "#We set a threshold value and find the important variables\n",
    "#give important variables for noise reduction\n",
    "print(\"important Columns:\")\n",
    "\n",
    "for feature_list_index in sfm1.get_support(indices=True):\n",
    "    print(X_train.columns[feature_list_index])\n",
    "\n",
    "X_important_train = sfm1.transform(X_train)\n",
    "X_important_test = sfm1.transform(X_test)\n",
    "\n",
    "clf1.fit(X_important_train,y_train)\n",
    "y_important_pred1 = clf1.predict(X_important_test)\n",
    "\n",
    "print(\"important Columns Accuracy:\")\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "print(accuracy_score(y_test, y_important_pred1))\n",
    "\n",
    "print(\"important Columns AUC:\")\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_important_pred1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01} , AUC: 0.748990286924857\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "Cs = [0.1, 1, 10] #C values for simplicity of model\n",
    "gammas = [0.01, 1, 10] #We will trade off the influence far or close of the model with C\n",
    "nfolds = 5\n",
    "grid2 = {'C': Cs, 'gamma' : gammas}\n",
    "#grid_search = GridSearchCV(svm.SVC(kernel='rbf'), grid2, cv=nfolds)\n",
    "#grid_search.fit(X_train_Scl1, y_train)\n",
    "grid_search_AUC = GridSearchCV(svm.SVC(kernel='rbf'), grid2, cv=nfolds, scoring='roc_auc')\n",
    "grid_search_AUC.fit(X_train_Scl1, y_train)\n",
    "print(grid_search_AUC.best_params_,', AUC:', grid_search_AUC.best_score_) # best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5 , accuracy: 0.4743465634075508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# we do a linear regression on the filtered set\n",
    "#The model behaves badly. The relationship is very likely nonlinear and a gridsearch will likely not improve the \n",
    "#scores so much\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "linreg = linear_model.Lasso(alpha=.5)\n",
    "linreg.fit(X_train_Scl1, y_train)\n",
    "PredLinY = linreg.predict(X_test_Scl1) \n",
    "print('AUC:', sklearn.metrics.roc_auc_score(y_test, PredLinY.round()), ', accuracy:', accuracy_score(y_test, PredLinY.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=1, probability=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#scaler = MinMaxScaler()\n",
    "X = Mod_seasons.loc[:,Mod_seasons.columns != 'Results_1'] # Trainning columns\n",
    "y = Mod_seasons.Results_1 #testing columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) # split for trainning\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_Scl1 = scaler.fit_transform(X_train) #scaling the data since the distances and the weights \n",
    "X_test_Scl1 = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#X_scl = scaler.fit_transform(X)\n",
    "#Y = X_scl\n",
    "model = svm.SVC(kernel='rbf', gamma = 1, C = 1, probability=True)\n",
    "model.fit(X_train_Scl1, y_train)\n",
    "#Y = model.predict(X_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=40, tol=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2018-2019 check\n",
    "\n",
    "Seasons4.reset_index(inplace = True)\n",
    "a_ind_1 = Seasons4[['Date_x', 'Win_x','Loss_x']].drop_duplicates().index\n",
    "Seasons4 = Seasons4[Seasons4.index.isin(a_ind_1)]\n",
    "Mod_seasons_check = Seasons4.iloc[:,18:]\n",
    "X_ch = Mod_seasons_check.loc[:,Mod_seasons_check.columns != 'Results_1']\n",
    "y_ch = Mod_seasons_check.Results_1\n",
    "X_ch_scl = scaler.fit_transform(X_ch)\n",
    "lr = LogisticRegression(penalty='l2', max_iter=40, tol=5, C = 1, solver = 'lbfgs' )\n",
    "lr.fit(X_train_Scl1, y_train)\n",
    "#model = svm.SVC(kernel='rbf', gamma = 1, C = 1, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monetary Gains of individual\n",
    "\n",
    "In the first column below, we use logistic regression to make predictions on the 2019 games with the command:\n",
    "\n",
    "Y_ch = lr.predict(X_ch_scl)\n",
    "\n",
    "\n",
    "\n",
    "In the second cell below we have the command:\n",
    "  \n",
    "     for i in range(len(Proba[:35])):\n",
    "\n",
    "with len(Proba[:35]) helping us find a range of game on which to be placing bets (35 first games of 2019) we find out that placing bets of $20 on each game would help us achieve total gains of $95 (or a 34% interest rate) \n",
    "compared to placing bets on the entire season of 2019 that yield $1036 at the end of the season, or an interest rate of approximately 8.8%\n",
    "\n",
    "Note that better performance can be achieved with SVC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47784045124899277"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ch = lr.predict(X_ch_scl)\n",
    "Y_ch = pd.Series(Y_ch)\n",
    "y_ch1 = y_ch.reset_index()\n",
    "\n",
    "diff = []\n",
    "\n",
    "for i in range(len(Y_ch)):\n",
    "    d = Y_ch[i]-y_ch1.Results_1.loc[i]\n",
    "    diff.append(d)\n",
    "\n",
    "diff = abs(pd.Series(diff))\n",
    "diff.sum()/len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ch_1 = []\n",
    "ind_w = []\n",
    "ind_l = []\n",
    "gain = []\n",
    "loss = []\n",
    "Proba = lr.predict_proba(X_ch_scl)\n",
    "for i in range(len(Proba[:35])):\n",
    "    if Proba[i][1] > .5:\n",
    "        Y_ch_1.append(1)\n",
    "        if Proba[i][1] > .7:\n",
    "            ind_w.extend([[i,1,Proba[i][1]]])\n",
    "    else:\n",
    "        Y_ch_1.append(0)\n",
    "        if Proba[i][0] > .7:\n",
    "            ind_l.extend([[i,0,Proba[i][0]]])\n",
    "            \n",
    "diff = []\n",
    "\n",
    "for i in range(len(Y_ch_1)):\n",
    "    d = Y_ch_1[i]-y_ch1.Results_1.loc[i]\n",
    "    #if d != 0\n",
    "    diff.append(d)\n",
    "\n",
    "diff = abs(pd.Series(diff))\n",
    "diff.sum()/len(diff)\n",
    "\n",
    "for i in range(len(ind_w)):\n",
    "    if y_ch1.Results_1.loc[ind_w[i][0]] - 1 == 0:\n",
    "        gain.append(ind_w[i][2])\n",
    "    else: \n",
    "        loss.append(-1*ind_w[i][2])\n",
    "for i in range(len(ind_l)):\n",
    "    if y_ch1.Results_1.loc[ind_l[i][0]] - 0 == 0:\n",
    "        gain.append(ind_l[i][2])\n",
    "    else: \n",
    "        loss.append(-1*ind_l[i][2])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.41398875811194 4 10 280\n",
      "The interest rate is: 34.076424556468545 %\n"
     ]
    }
   ],
   "source": [
    "print((pd.Series(loss).sum()+pd.Series(gain).sum())*20, len(loss), len(gain), 20*(len(loss)+len(gain)))\n",
    "#print('The interest rate is:', (pd.Series(loss[:50]).sum()+pd.Series(gain[:50]).sum())*100/len(loss[:50]),'%')\n",
    "print('The interest rate is:', (pd.Series(loss).sum()+pd.Series(gain).sum())*100/(len(loss)+len(gain)),'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the games quotes are not considered here.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
